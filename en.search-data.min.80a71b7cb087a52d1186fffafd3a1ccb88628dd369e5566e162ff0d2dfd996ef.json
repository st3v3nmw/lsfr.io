[{"id":0,"href":"/guides/cli/","title":"CLI","section":"Guides","content":"CLI# Installation# go install# $ go install github.com/st3v3nmw/lsfr/cmd/lsfr@latest This installs lsfr to your $GOPATH/bin directory. Make sure it\u0026rsquo;s in your $PATH.\nVerify Installation# $ lsfr list Available challenges: kv-store - Distributed Key-Value Store (8 stages) Start with: lsfr new \u0026lt;challenge-name\u0026gt; Next Steps# Start your first challenge:\n$ lsfr new kv-store $ cd kv-store $ lsfr test "},{"id":1,"href":"/how-lsfr-works/","title":"How lsfr Works","section":"Home","content":"How lsfr Works# Reading about how systems work is one thing. Building them is another.\nlsfr breaks down complex systems into stages you can actually implement. Build a distributed database, write a compiler, or create a message queue from scratch. Each challenge starts simple and adds complexity one stage at a time.\nYou write real code that actually works. Tests verify your implementation handles the hard problems: network failures, crash recovery, concurrent access, etc. By the end, you understand these systems because you\u0026rsquo;ve built them yourself.\nChallenges# Each challenge breaks down a complex system into manageable stages that can be built incrementally. For instance, the distributed key-value store challenge starts with a simple in-memory store with a HTTP API and by the end, you have a sharded distributed key-value store.\nEach stage comes with tests that simulate real-world scenarios like network failures and crash recovery. The tests verify your system\u0026rsquo;s behavior, not implementation details, so you\u0026rsquo;re free to choose your own data structures, algorithms, and approaches. These are essentially end-to-end tests that check if your system actually works.\nEach stage explains what you need to implement and links out to good resources for learning more. Why reinvent the wheel when Kleppmann and others have already explained it better? ðŸ˜…\nReady to try it out? Here\u0026rsquo;s how to set up lsfr and start your first challenge.\nInstallation# See this guide on how to install lsfr on your system.\nPick a Challenge# Start with the distributed key-value store challenge; it\u0026rsquo;s a great introduction to distributed systems concepts. Check the challenge\u0026rsquo;s page for details on the first stage.\nScaffolding# Run lsfr new kv-store to create a new challenge directory with:\nrun.sh - Builds and runs your implementation README.md - Challenge overview and requirements lsfr.yaml - Tracks your progress Update run.sh with the commands to build and run your implementation. You can use any language - Go, Python, Rust, even Ponylang - as long as run.sh can start your program and pass through any command-line arguments from lsfr test.\nImplement \u0026amp; Test# Write your implementation in any language to solve the challenge\u0026rsquo;s first stage. When ready, run lsfr test to verify your solution works correctly. The tests focus on behavior, not implementation details.\nAdvance Through Stages# Pass the current stage, then run lsfr next to unlock the next stage. Each stage builds on the previous one, gradually adding complexity.\nBy the end of the challenge, you\u0026rsquo;ll have a deep understanding of how these systems actually work because you built one yourself.\nGood luck! ðŸš€\n"},{"id":2,"href":"/kv-store/http-api/","title":"HTTP API","section":"Distributed Key-Value Store","content":"HTTP API# In this stage, you\u0026rsquo;ll build an in-memory key-value store and expose it over a REST API.\nEndpoints# You\u0026rsquo;ll implement the following endpoints:\nPUT /kv/{key} Add or update a key-value pair in the store.\nPUT /kv/{key} Parameters: - key (path, required): The key to store (cannot be empty) Body: Value to store as plain text (cannot be empty) Response: - 200 OK: Key-value pair added or updated successfully - 400 Bad Request: Return \u0026#34;key cannot be empty\\n\u0026#34; or \u0026#34;value cannot be empty\\n\u0026#34; GET /kv/{key} Retrieve the value associated with the given key.\nGET /kv/{key} Parameters: - key (path, required): The key to retrieve Response: - 200 OK: Return the stored value - 404 Not Found: Return \u0026#34;key not found\\n\u0026#34; DELETE /kv/{key} Remove a key-value pair from the store.\nDELETE /kv/{key} Parameters: - key (path, required): The key to delete Response: - 200 OK: Key deleted successfully (or key didn\u0026#39;t exist) DELETE /clear Remove all key-value pairs from the store.\nDELETE /clear Response: - 200 OK: All keys cleared successfully Error Handling Unsupported HTTP methods on any endpoint should return:\n405 Method Not Allowed: Return \u0026ldquo;method not allowed\\n\u0026rdquo; Your API should handle concurrent requests safely. Consider thread safety when implementing your in-memory store.\nStorage# A simple in-memory map/dictionary is sufficient for storage in this stage. You\u0026rsquo;ll add persistence in the next stage.\nData Model# Keys and values are stored as simple strings. This keeps the data model straightforward so you can focus on building intuition in distributed systems, not implementing complex data types.\nKeys# Keys must be URL-safe strings without spaces or forward slashes. Examples of valid keys:\ncountry:capital user_123 special:key-with_symbols.123 Values# Values are stored as UTF-8 encoded text and can contain:\nUnicode characters like ðŸ˜Š Spaces and special symbols Long strings (up to reasonable memory limits) Testing# Your server must accept --port and --working-dir flags:\n$ ./run.sh --port 8080 --working-dir .lsfr/run-20251226-210357 --working-dir is your server\u0026rsquo;s working directory. Any files you create should go here, and your server\u0026rsquo;s logs will be in primary.log.\nYou can test your implementation using the lsfr command:\n$ lsfr test http-api Testing http-api: HTTP API with GET/PUT/DELETE Operations âœ“ PUT Basic Operations âœ“ PUT Edge and Error Cases âœ“ GET Basic Operations âœ“ GET Edge and Error Cases âœ“ DELETE Basic Operations âœ“ DELETE Edge and Error Cases âœ“ CLEAR Operations âœ“ Concurrent Operations - Different Keys âœ“ Concurrent Operations - Same Key âœ“ Check Allowed HTTP Methods PASSED âœ“ Run \u0026#39;lsfr next\u0026#39; to advance to the next stage. Debugging# When tests fail, lsfr will show you exactly what went wrong:\n$ lsfr test Testing http-api: HTTP API with GET/PUT/DELETE Operations âœ“ PUT Basic Operations âœ“ PUT Edge and Error Cases âœ“ GET Basic Operations âœ— GET Edge and Error Cases GET http://127.0.0.1:42409/kv/nonexistent:key Expected response: \u0026#34;key not found\\n\u0026#34; Actual response: \u0026#34;\\n\u0026#34; Your server should return 404 Not Found when a key doesn\u0026#39;t exist. Check your key lookup logic and error handling. FAILED âœ— Read the guide: lsfr.io/kv-store/http-api You can also add your own logging to help debug. Your server\u0026rsquo;s output (stdout/stderr) is captured in primary.log inside the working directory.\n"},{"id":3,"href":"/reference/testing/","title":"Testing","section":"Reference","content":"Testing# // TODO\n"},{"id":4,"href":"/guides/ci-cd/","title":"CI/CD","section":"Guides","content":"CI/CD# Run lsfr tests automatically in GitHub Actions.\nGitHub Actions# Add .github/workflows/lsfr.yaml to your repository:\nname: lsfr Tests on: push: branches: [main] pull_request: branches: [main] jobs: test: runs-on: ubuntu-latest steps: - uses: actions/checkout@v6 - uses: st3v3nmw/lsfr-action@mainThe action runs lsfr test on every push to main and on pull requests.\nCustom Working Directory# If your lsfr.yaml isn\u0026rsquo;t at the repository root:\n- uses: st3v3nmw/lsfr-action@main with: working-directory: \u0026#39;./my-challenge\u0026#39;"},{"id":5,"href":"/kv-store/","title":"Distributed Key-Value Store","section":"Home","content":"Distributed Key-Value Store Challenge# Welcome to the distributed key-value store challenge!\nIn this challenge, you\u0026rsquo;ll build a distributed key-value store from scratch. You\u0026rsquo;ll start with a simple HTTP API and progressively add persistence, crash recovery, clustering, replication, and consensus mechanisms.\nBy the end, you\u0026rsquo;ll have built a system that can handle node failures, network partitions, and scale across multiple nodes while maintaining data consistency.\nStages# HTTP API Build a basic in-memory key-value store with GET/PUT/DELETE operations over HTTP.\nPersistence Add durability to your store. Data should survive clean shutdowns (SIGTERM).\nCrash Recovery Ensure data consistency after crashes. Data should survive unclean shutdowns (SIGKILL).\nClustering Discover and connect to other nodes in a leader-follower arrangement.\nRead Replicas Add read replicas that follow the leader. Handle eventual consistency across the cluster.\nFault Tolerance Handle leader failures and network partitions while maintaining cluster consistency.\nStrong Consistency Implement strong consistency guarantees for read and write operations.\nSharding Distribute data across multiple shards for horizontal scaling.\nGetting Started# If you haven\u0026rsquo;t already, read this overview on how lsfr works and then start with stage 1 (HTTP API).\nResources# Books# Designing Data-Intensive Applications by Martin Kleppmann Database Internals by Alex Petrov Videos# Distributed Systems lecture series by Martin Kleppmann Implementations# little-key-value in Go by @st3v3nmw "},{"id":6,"href":"/kv-store/persistence/","title":"Persistence","section":"Distributed Key-Value Store","content":"Persistence# In this stage, you\u0026rsquo;ll add persistence to your key-value store. Data should survive clean shutdowns and be restored when the server restarts.\nGraceful Shutdown# When your server receives a SIGTERM signal, it should:\nWait for in-flight requests to complete (within 5 seconds) Save all key-value pairs to disk Exit with status code 0 Startup Recovery# When your server starts, it should:\nCheck the working directory for existing data Load any previously saved key-value pairs Continue serving requests with the restored data If no previous data exists, start with an empty store.\nStorage# Save your in-memory state to disk during shutdown and restore it on startup. Create your data files in the working directory (passed via --working-dir). The serialization format and file naming are up to you - JSON, binary, plain text, whatever.\nThis approach survives clean shutdowns but not crashes. If the process dies unexpectedly, you\u0026rsquo;ll lose any data that wasn\u0026rsquo;t saved. That\u0026rsquo;s fine for this stage - you\u0026rsquo;ll add crash recovery in the next stage.\nTesting# Your server will be started with the working directory where it should store data:\n$ ./run.sh --port 8080 --working-dir .lsfr/run-20251226-210357 You can test your implementation using the lsfr command:\n$ lsfr test Testing persistence: Data Survives SIGTERM âœ“ Store Initial Testing Data âœ“ Verify Data Survives Restart âœ“ Check Data Integrity After Multiple Restarts âœ“ Test Persistence When Under Load PASSED âœ“ Run \u0026#39;lsfr next\u0026#39; to advance to the next stage. The test will:\nStore data in your server Send SIGTERM to trigger graceful shutdown Restart your server Verify all data is still present "},{"id":7,"href":"/reference/writing-style/","title":"Writing Style","section":"Reference","content":"Writing Style# Audience# Write for capable peers: mid-level+ developers who can research concepts, make implementation choices, and work on complex problems.\nState what the system needs to accomplish, not how to build it. Point to possible approaches or considerations, but let readers make implementation choices.\nPedagogy# Structure learning through progressive disclosure. Start each challenge with the simplest version of a problem, then add complexity only after the foundation is solid. Make each stage build on previous work so the progression feels natural rather than arbitrary.\nIntroduce one major capability per stage: one testable system behavior that builds on previous work. Supporting concepts can appear as needed, but each stage should add one clear building block to the system.\nConstrain interfaces and contracts that affect testing or compatibility. Leave internal implementation details (data structures, algorithms, optimizations) to the reader\u0026rsquo;s judgment.\nLink to external resources when you introduce concepts. Point to tutorials, papers, lectures, or reference implementations - whatever explains it best. Don\u0026rsquo;t replicate explanations that already exist; point to the best resource and move on.\nVoice \u0026amp; Tone# Address the reader directly using second person (\u0026ldquo;you\u0026rdquo;) and active voice. Write as if you\u0026rsquo;re giving clear directions to a colleague, not lecturing from a podium. Use simple, everyday language.\nGet to the point immediately. Skip introductory context about why topics are important - your reader already has that context. Brief section transitions are fine, but avoid elaborate setup. Do explain the reasoning behind specific constraints or design choices you\u0026rsquo;re imposing.\nMaintain a matter-of-fact tone. Skip reassurance and cheerleading. An occasional emoji or light moment is fine, but default to straightforward instruction.\nFormatting# Structure each stage with a brief introduction (one or two sentences on what the reader will build), followed by precise specifications, implementation guidance, and testing instructions. Optionally include a debugging section with example test failures or debugging techniques. When showing failures, provide actionable guidance: expected versus actual output, then what to check or what might have gone wrong.\nWhen defining API contracts, data formats, or expected behaviors, be exact. Include complete endpoint specifications with methods, parameters, responses, and literal error messages. Specify data constraints explicitly. The goal is removing ambiguity about what to build without prescribing how to build it.\nUse code blocks to show test invocations, command-line usage, and expected outputs - not implementation code or algorithms. Readers should see how to verify their work and what correct behavior looks like. When test behavior isn\u0026rsquo;t obvious from output alone, briefly explain what the test does, especially when it affects implementation constraints (which signals, timing requirements, error conditions to handle).\nReserve callouts for critical non-obvious concerns. Don\u0026rsquo;t use them for general information that belongs in body text.\nLink concepts inline when they first appear. Add comprehensive resources like books, lecture series, \u0026amp; reference implementations to the challenge\u0026rsquo;s index page.\n"},{"id":8,"href":"/kv-store/crash-recovery/","title":"Crash Recovery","section":"Distributed Key-Value Store","content":"Crash Recovery# Your server currently saves data on clean shutdown but loses everything if it crashes. In this stage, you\u0026rsquo;ll add durability so data survives unexpected failures.\nWrite-Ahead Logging# Implement a Write-Ahead Log (WAL) that records operations before they\u0026rsquo;re applied to memory. Each write operation must be written to the log file before updating your in-memory store.\nLog Format# Your log should record operations in append-only fashion. The format is up to you - JSONL (one JSON object per line), binary serialization, or plain text all work.\nEach log entry needs enough information to replay the operation:\nOperation type (e.g., \u0026ldquo;set\u0026rdquo;, \u0026ldquo;delete\u0026rdquo;, \u0026ldquo;clear\u0026rdquo;) Key Value Any other metadata you need for replay Durability# After appending an operation to the log, ensure it\u0026rsquo;s physically written to disk before responding to the client. Use your language\u0026rsquo;s file sync mechanism (fsync, flush, etc.) to force the operating system to persist the write.\nWithout sync, the OS may buffer writes in memory and you\u0026rsquo;ll lose data on crash.\nSyncing on every operation is slow since you\u0026rsquo;re forcing a disk write and blocking the response. This is the correct trade-off for durability, but it limits throughput. Production databases use techniques like batching to amortize the fsync cost across multiple operations.\nRecovery Procedure# When your server starts:\nLoad the most recent snapshot (from the persistence stage) if one exists Replay all operations from the WAL that occurred after the snapshot Resume serving requests If no snapshot exists, replay the entire log from the beginning.\nHandling Corrupted Logs# The log file may contain partial writes at the end if the server crashed mid-write. Your replay logic should handle this gracefully:\nSkip incomplete/corrupted entries at the end of the log Process all valid entries before the corruption Continue serving requests with the recovered data Checkpointing# As your log grows, replaying from the beginning becomes slow. Periodically create snapshots of your in-memory state and truncate the log.\nWhen to checkpoint is up to you - after N operations, every M seconds, when the log reaches a certain size, etc. The test doesn\u0026rsquo;t care about your checkpoint strategy, only that recovery works correctly.\nAfter creating a snapshot:\nWrite the snapshot to a new file Truncate or create a new WAL file Continue logging operations On recovery, load the latest snapshot and replay only the operations logged after that snapshot.\nDon\u0026rsquo;t delete the old snapshot until the new one is safely on disk. If you crash during checkpointing, you need the old snapshot and log to be intact.\nStorage Layout# You now have two types of files:\nSnapshot: Full state at a point in time (from previous stage) WAL: Operations logged since the last snapshot Organize these in the working directory however makes sense - separate files, subdirectories, naming conventions, etc. The test only cares that recovery works, not how you structure the files.\nTesting# Your server will be started with the working directory:\n$ ./run.sh --port 8080 --working-dir .lsfr/run-20251226-210357 Your server will be tested with unexpected crashes:\n$ lsfr test crash-recovery Testing crash-recovery: Write-Ahead Logging and Recovery âœ“ Basic WAL Durability âœ“ Recovery After Crash âœ“ Multiple Crash Recovery Cycles âœ“ Checkpoint and Replay âœ“ Corrupted Log Handling PASSED âœ“ Run \u0026#39;lsfr next\u0026#39; to advance to the next stage. The test will:\nSend PUT/DELETE/CLEAR operations to your server Kill the server process (SIGKILL) without warning Restart your server Verify all data that was acknowledged before the crash is still present Debugging# When tests fail, lsfr shows what data was lost:\n$ lsfr test crash-recovery Testing crash-recovery: Write-Ahead Logging and Recovery âœ“ Basic WAL Durability âœ— Recovery After Crash Before crash: PUT /kv/user_123 â†’ \u0026#34;alice\u0026#34; After crash: GET /kv/user_123 â†’ 404 Not Found Your server acknowledged the PUT but lost the data after crashing. Make sure you\u0026#39;re syncing the WAL to disk (fsync) before responding to writes. FAILED âœ— Read the guide: lsfr.io/kv-store/crash-recovery "},{"id":9,"href":"/kv-store/clustering/","title":"Clustering","section":"Distributed Key-Value Store","content":"Clustering# // TODO\n"},{"id":10,"href":"/kv-store/read-replicas/","title":"Read Replicas","section":"Distributed Key-Value Store","content":"Read Replicas# // TODO\n"},{"id":11,"href":"/kv-store/fault-tolerance/","title":"Fault Tolerance","section":"Distributed Key-Value Store","content":"Fault Tolerance# // TODO\n"},{"id":12,"href":"/kv-store/strong-consistency/","title":"Strong Consistency","section":"Distributed Key-Value Store","content":"Strong Consistency# // TODO\n"},{"id":13,"href":"/kv-store/sharding/","title":"Sharding","section":"Distributed Key-Value Store","content":"Sharding# // TODO\n"},{"id":14,"href":"/about/","title":"About","section":"Home","content":"About# lsfr /ËˆÉ›l ËˆÉ›s ËˆÉ›f ËˆÉ‘r/ noun\nNamed after the song \u0026ldquo;Love Songs For Robots\u0026rdquo; by Patrick Watson.\nI have always been interested in distributed systems so when I finally got around to reading Designing Data-Intensive Applications, I thought \u0026ldquo;you know what, I should actually build some of this stuff to really understand it\u0026rdquo;. And that\u0026rsquo;s how lsfr was born: it breaks down complex systems into stages you can implement and test.\nBuilt by Stephen Mwangi.\n"}]